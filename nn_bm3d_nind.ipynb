{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w2NhTSNWMOO",
    "outputId": "2fb96042-568c-4df3-e4cf-45d5b07c3d39",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting bm3d\n",
      "  Downloading bm3d-3.0.9-py3-none-any.whl (8.4 MB)\n",
      "\u001B[K     |████████████████████████████████| 8.4 MB 4.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.7.3)\n",
      "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from bm3d) (1.3.0)\n",
      "Installing collected packages: bm3d\n",
      "Successfully installed bm3d-3.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fj3EEEkPYaxV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class inconv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class up_no_skip(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up_no_skip, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffY // 2, diffY - diffY // 2, \n",
    "                        diffX // 2, diffX - diffX // 2), 'replicate')\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class outconv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.inc(x)\n",
    "        self.x2 = self.down1(self.x1)\n",
    "        self.x3 = self.down2(self.x2)\n",
    "        self.x4 = self.down3(self.x3)\n",
    "        self.x5 = self.down4(self.x4)\n",
    "        self.x6 = self.up1(self.x5, self.x4)\n",
    "        self.x7 = self.up2(self.x6, self.x3)\n",
    "        self.x8 = self.up3(self.x7, self.x2)\n",
    "        self.x9 = self.up4(self.x8, self.x1)\n",
    "        self.y = self.outc(self.x9)\n",
    "        if self.need_sigmoid:\n",
    "            self.y = torch.sigmoid(self.y)\n",
    "\n",
    "        return self.y\n",
    "    \n",
    "class UNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet5, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 1024)\n",
    "        self.down5 = down(1024, 1024)\n",
    "        self.up1 = up(2048, 512)\n",
    "        self.up2 = up(1024, 256)\n",
    "        self.up3 = up(512, 128)\n",
    "        self.up4 = up(256, 64)\n",
    "        self.up5 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.inc(x)\n",
    "        self.x2 = self.down1(self.x1)\n",
    "        self.x3 = self.down2(self.x2)\n",
    "        self.x4 = self.down3(self.x3)\n",
    "        self.x5 = self.down4(self.x4)\n",
    "        self.x6 = self.down5(self.x5)\n",
    "        self.x7 = self.up1(self.x6, self.x5)\n",
    "        self.x8 = self.up2(self.x7, self.x4)\n",
    "        self.x9 = self.up3(self.x8, self.x3)\n",
    "        self.x10 = self.up4(self.x9, self.x2)\n",
    "        self.x11 = self.up5(self.x10, self.x1)\n",
    "        self.y = self.outc(self.x11)\n",
    "        if self.need_sigmoid:\n",
    "            self.y = torch.sigmoid(self.y)\n",
    "\n",
    "        return self.y    \n",
    "\n",
    "    \n",
    "class UNet3(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet3, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 256)\n",
    "        self.up1 = up(512, 128)\n",
    "        self.up2 = up(256, 64)\n",
    "        self.up3 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.inc(x)\n",
    "        self.x2 = self.down1(self.x1)\n",
    "        self.x3 = self.down2(self.x2)\n",
    "        self.x4 = self.down3(self.x3)\n",
    "        self.x5 = self.up1(self.x4, self.x3)\n",
    "        self.x6 = self.up2(self.x5, self.x2)\n",
    "        self.x7 = self.up3(self.x6, self.x1)\n",
    "        self.y = self.outc(self.x7)\n",
    "        if self.need_sigmoid:\n",
    "            self.y = torch.sigmoid(self.y)\n",
    "\n",
    "        return self.y\n",
    "    \n",
    "class UNet2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet2, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 128)\n",
    "        self.up1 = up(256, 64)\n",
    "        self.up2 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.inc(x)\n",
    "        self.x2 = self.down1(self.x1)\n",
    "        self.x3 = self.down2(self.x2)\n",
    "        self.x4 = self.up1(self.x3, self.x2)\n",
    "        self.x5 = self.up2(self.x4, self.x1)\n",
    "        self.y = self.outc(self.x5)\n",
    "        if self.need_sigmoid:\n",
    "            self.y = torch.sigmoid(self.y)\n",
    "\n",
    "        return self.y    \n",
    "\n",
    "class UNet5_no_skip(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet5_no_skip, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 1024)\n",
    "        self.down5 = down(1024, 1024)\n",
    "        self.up1 = up_no_skip(1024, 1024)\n",
    "        self.up2 = up_no_skip(1024, 512)\n",
    "        self.up3 = up_no_skip(512, 256)\n",
    "        self.up4 = up_no_skip(256, 128)\n",
    "        self.up5 = up_no_skip(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.down4(x)\n",
    "        x = self.down5(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.up4(x)\n",
    "        x = self.up5(x)\n",
    "        y = self.outc(x)\n",
    "        if self.need_sigmoid:\n",
    "            y = torch.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "class UNet_no_skip(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet_no_skip, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up_no_skip(512, 512)\n",
    "        self.up2 = up_no_skip(512, 256)\n",
    "        self.up3 = up_no_skip(256, 128)\n",
    "        self.up4 = up_no_skip(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.down4(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.up4(x)\n",
    "        y = self.outc(x)\n",
    "        if self.need_sigmoid:\n",
    "            y = torch.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "class UNet3_no_skip(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet3_no_skip, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 256)\n",
    "        self.up1 = up_no_skip(256, 256)\n",
    "        self.up2 = up_no_skip(256, 128)\n",
    "        self.up3 = up_no_skip(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        y = self.outc(x)\n",
    "        if self.need_sigmoid:\n",
    "            y = torch.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "class UNet2_no_skip(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels, n_classes, need_sigmoid=False):\n",
    "        super(UNet2_no_skip, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 128)\n",
    "        self.up1 = up_no_skip(128, 128)\n",
    "        self.up2 = up_no_skip(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        y = self.outc(x)\n",
    "        if self.need_sigmoid:\n",
    "            y = torch.sigmoid(y)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "8VnYRXV8WFYJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import bm3d\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7ikKCeyXWFYM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pil_to_np(img_pil, normalize=False):\n",
    "    img_np = np.array(img_pil)\n",
    "    if normalize:\n",
    "        img_np = img_np / 255\n",
    "\n",
    "    if len(img_np.shape) == 2:\n",
    "        return img_np.astype(np.float)\n",
    "    else:\n",
    "        return img_np.transpose(2, 0, 1).astype(np.float)\n",
    "\n",
    "def np_to_pil(img_np, normalize=False):\n",
    "    if normalize:\n",
    "        img_np = img_np*255\n",
    "\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "\n",
    "    if len(img_np.shape) == 2:\n",
    "        img_pil = Image.fromarray(img_np)\n",
    "    else:\n",
    "        img_pil = Image.fromarray(img_np.transpose(1, 2, 0))\n",
    "\n",
    "    return img_pil\n",
    "\n",
    "def np_to_torch(img_np):\n",
    "    if len(img_np.shape) == 2:\n",
    "        return torch.Tensor(img_np)[None, None, ...]\n",
    "    else:\n",
    "        return torch.Tensor(img_np)[None, ...]\n",
    "\n",
    "def torch_to_np(img_torch):\n",
    "    return img_torch.cpu().squeeze().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B_3kNkLeWFYN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_hist(x, root):\n",
    "    x = x.flatten()\n",
    "    plt.figure()\n",
    "    n, bins, patches = plt.hist(x, bins=128, density=1)\n",
    "    plt.savefig(root)\n",
    "    plt.close()\n",
    "\n",
    "def save_heatmap(image_np, root):\n",
    "    cmap = plt.get_cmap('jet')\n",
    "\n",
    "    rgba_img = cmap(image_np)\n",
    "    rgb_img = np.delete(rgba_img, 3, 2)\n",
    "    rgb_img_pil = Image.fromarray((255*rgb_img).astype(np.uint8))\n",
    "    rgb_img_pil.save(root)\n",
    "\n",
    "def sample_z(mean):\n",
    "    eps = mean.clone().normal_()\n",
    "\n",
    "    return mean + eps\n",
    "\n",
    "def eval_sigma(num_iter, noise_level):\n",
    "    if num_iter == 1:\n",
    "        sigma = noise_level\n",
    "    else:\n",
    "        sigma = 5\n",
    "\n",
    "    return sigma\n",
    "\n",
    "def save_torch(img_torch, root):\n",
    "    img_np = torch_to_np(img_torch)\n",
    "    img_pil = np_to_pil(img_np)\n",
    "    img_pil.save(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aQGFHhVuWFYO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def denoising(noise_im, clean_im, LR=1e-2, sigma=3, rho=1, eta=0.5, total_step=30,\n",
    "              prob1_iter=500, noise_level=None, result_root=None, f=None):\n",
    "\n",
    "    sig=3\n",
    "    r_bm3d = bm3d.bm3d_rgb(noise_im.transpose(1, 2, 0), sig)\n",
    "    r_bm3d = np.clip(r_bm3d, 0, 255)\n",
    "    psnr_bm3d = peak_signal_noise_ratio(clean_im.transpose(1, 2, 0), r_bm3d, data_range=255)\n",
    "    ssim_bm3d = structural_similarity(r_bm3d, clean_im.transpose(1, 2, 0), multichannel=True, data_range=255)\n",
    "\n",
    "    print('noise level {} '.format(noise_level), file=f, flush=True)\n",
    "    print('PSNR_BM3D: {}, SSIM_BM3D: {}'.format(psnr_bm3d, ssim_bm3d), file=f, flush=True)\n",
    "\n",
    "    r_bm3d = Image.fromarray(r_bm3d.astype(np.uint8))\n",
    "    r_bm3d.save(result_root + 'bm3d_result.png')\n",
    "\n",
    "\n",
    "    input_depth = 3\n",
    "    latent_dim = 3\n",
    "\n",
    "    en_net = UNet(input_depth, latent_dim).cuda()\n",
    "    de_net = UNet(latent_dim, input_depth).cuda()\n",
    "\n",
    "    parameters = [p for p in en_net.parameters()] + [p for p in de_net.parameters()]\n",
    "    optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "\n",
    "    l2_loss = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    i0 = np_to_torch(noise_im).cuda()\n",
    "    noise_im_torch = np_to_torch(noise_im).cuda()\n",
    "    i0_til_torch = np_to_torch(noise_im).cuda()\n",
    "    Y = torch.zeros_like(noise_im_torch).cuda()\n",
    "\n",
    "    best_psnr = 0\n",
    "    best_pil = None\n",
    "\n",
    "    for i in range(total_step):\n",
    "\n",
    "################################# sub-problem 1 ###############################\n",
    "\n",
    "        for i_1 in range(prob1_iter):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            mean = en_net(noise_im_torch)\n",
    "            z = sample_z(mean)\n",
    "            out = de_net(z)\n",
    "\n",
    "            total_loss =  0.5 * l2_loss(out, noise_im_torch)\n",
    "            total_loss += 0.5 * (1/sigma**2)*l2_loss(mean, i0)\n",
    "            total_loss += (rho/2) * l2_loss(i0 + Y, i0_til_torch)\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                i0 = ((1/sigma**2)*mean.detach() + rho*(i0_til_torch - Y)) / ((1/sigma**2) + rho)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "################################# sub-problem 2 ###############################\n",
    "\n",
    "            i0_np = torch_to_np(i0)\n",
    "            Y_np = torch_to_np(Y)\n",
    "\n",
    "            sig = eval_sigma(i+1, noise_level)\n",
    "\n",
    "            i0_til_np = bm3d.bm3d_rgb(i0_np.transpose(1, 2, 0) + Y_np.transpose(1, 2, 0), sig).transpose(2, 0, 1)\n",
    "            i0_til_torch = np_to_torch(i0_til_np).cuda()\n",
    "\n",
    "################################# sub-problem 3 ###############################\n",
    "\n",
    "            Y = Y + eta * (i0 - i0_til_torch)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "            Y_name = 'Y_{:04d}'.format(i) + '.png'\n",
    "            i0_name = 'i0_num_epoch_{:04d}'.format(i) + '.png'\n",
    "            mean_name = 'Latent_im_num_epoch_{:04d}'.format(i) + '.png'\n",
    "            out_name = 'res_of_dec_num_epoch_{:04d}'.format(i) + '.png'\n",
    "            diff_name = 'Latent_dis_num_epoch_{:04d}'.format(i) + '.png'\n",
    "\n",
    "            # Y_np = torch_to_np(Y)\n",
    "            # Y_norm_np = np.sqrt((Y_np*Y_np).sum(0))\n",
    "            # save_heatmap(Y_norm_np, result_root + Y_name)\n",
    "\n",
    "            # save_torch(mean, result_root + mean_name)\n",
    "            # save_torch(out, result_root + out_name)\n",
    "            # save_torch(i0, result_root + i0_name)\n",
    "\n",
    "\n",
    "            i0_til_np = torch_to_np(i0_til_torch).clip(0, 255)\n",
    "            psnr = peak_signal_noise_ratio(clean_im.transpose(1, 2, 0), i0_til_np.transpose(1, 2, 0), data_range=255)\n",
    "            ssim = structural_similarity(clean_im.transpose(1, 2, 0), i0_til_np.transpose(1, 2, 0), multichannel=True, data_range=255)\n",
    "\n",
    "            i0_til_pil = np_to_pil(i0_til_np)\n",
    "            if i % 3 == 0:\n",
    "              i0_til_pil.save(os.path.join(result_root, '{}'.format(i) + '.jpg'))\n",
    "\n",
    "            print('Iteration: {:02d}, VAE Loss: {:f}, PSNR: {:f}, SSIM: {:f}'.format(i, total_loss.item(), psnr, ssim), file=f, flush=True)\n",
    "\n",
    "    best_psnr = psnr\n",
    "    best_ssim = ssim\n",
    "    best_pil = i0_til_pil\n",
    "    best_pil.save(os.path.join(result_root, '{}.jpg'.format(i)))\n",
    "                \n",
    "\n",
    "    return best_psnr, best_ssim , psnr_bm3d , ssim_bm3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "m85iayXcWFYQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run new denoising approach for NIND dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHyUO0nuWFYR",
    "outputId": "d815030d-3349-4900-dd75-cca2ceaa4dfa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PeC0QYkaE7z",
    "outputId": "828dfcb5-0a58-4499-f57f-d0efd99f72ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tiJDPR6raRIU",
    "outputId": "8ce3b064-e912-4ce9-e431-2b167c721c35",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Tesla T4'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4h98jCbWFYS",
    "outputId": "89d03a47-2434-4193-f648-27aca56e6a0f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if __name__ == '__main__':\n",
      "79it [2:38:36, 120.46s/it]\n"
     ]
    }
   ],
   "source": [
    "path = '/content/gdrive/MyDrive/NIND/'\n",
    "noises = sorted(glob.glob(path + '*noise.jpg'))\n",
    "cleans = sorted(glob.glob(path + '*clean.jpg'))\n",
    "\n",
    "LR = 1e-2\n",
    "sigma = 3\n",
    "rho = 1\n",
    "eta = 0.5\n",
    "total_step = 15\n",
    "prob1_iter = 20\n",
    "\n",
    "psnrs = []\n",
    "ssims = []\n",
    "bm3d_psnr = []\n",
    "bm3d_ssim = []\n",
    "\n",
    "for noise, clean in tqdm(zip(noises, cleans)):\n",
    "    \n",
    "    result = path + '/output/nn_bm3d_nind/{}/'.format(noise.split('/')[-1][:-9])\n",
    "    os.system('mkdir -p ' + result)\n",
    "\n",
    "    noise_im = Image.open(noise)\n",
    "    clean_im = Image.open(clean)\n",
    "\n",
    "    noise_im_np = pil_to_np(noise_im)\n",
    "    clean_im_np = pil_to_np(clean_im)\n",
    "\n",
    "    noise_level = 5\n",
    "    # noise_level = np.mean(estimate_sigma(noise_im_np.transpose(1, 2, 0), multichannel=True))\n",
    "\n",
    "    with open(result + 'result.txt', 'w') as f:\n",
    "        psnr, ssim, psnr_bm3d, ssim_bm3d = denoising(noise_im_np, clean_im_np, LR=LR, sigma=sigma,\n",
    "                                  rho=rho, eta=eta, total_step=total_step,\n",
    "                                  prob1_iter=prob1_iter, noise_level=noise_level,\n",
    "                                  result_root=result, f=f)\n",
    "\n",
    "        psnrs.append(psnr)\n",
    "        ssims.append(ssim)\n",
    "        bm3d_psnr.append(psnr_bm3d)\n",
    "        bm3d_ssim.append(ssim_bm3d)\n",
    "with open(path + '/output/nn_bm3d_nind/' + 'psnr_ssim.txt', 'w') as f:\n",
    "    print('AVG PSNR: {}'.format(sum(psnrs)/len(psnrs)), file=f, flush=True)\n",
    "    print('AVG SSIM: {}'.format(sum(ssims)/len(ssims)), file=f, flush=True)\n",
    "    print('AVG bm3d psnr =', sum(bm3d_psnr)/len(bm3d_psnr), file=f, flush=True)\n",
    "    print('AVG bm3d ssim =', sum(bm3d_ssim)/len(bm3d_ssim), file=f, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tzmGYVHzj5Cy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}